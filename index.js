// require modules
const fs = require('fs');
const { Client } = require('ssh2');
const archiver = require('archiver');
const { readFileSync } = require('fs');
const path = require('path');

// æ‰§è¡Œnodeè„šæœ¬çš„æ–‡ä»¶å¤¹ç›®å½• è¿™é‡Œéœ€è¦ä¸ºç›¸åº”çš„é¡¹ç›®çš„æ ¹ç›®å½•
const cwdPath = process.cwd();
// è¯»å–æœ¬å·¥å…·çš„é»˜è®¤é…ç½®
const configPlainText = readFileSync(path.resolve(__dirname, '.config.json'));
const CONFIG = JSON.parse(configPlainText);

/**
 * è¯»å–é¡¹ç›®çš„å‘å¸ƒé…ç½®æ–‡ä»¶
 *
 * @return {*} 
 */
function readConfigFile() {
  return require(path.resolve(cwdPath, CONFIG.CONFIG_FILE_NAME));
}

/**
 * ä¸Šä¼ æ–‡ä»¶
 *
 * @param {*} conn
 * @param {*} localPath
 * @param {*} remotePath
 * @param {*} callback
 */
function uploadFile(conn, localPath, remotePath, callback){
  conn.sftp((err, sftp) => {
    if (err) throw err;
    sftp.fastPut(localPath, remotePath, function(err, result) {
      if (err) throw err;
      callback(result)
    });
  })
}


/**
 * æ–‡ä»¶å‹ç¼©
 *
 * @param {*} localPath
 */
async function compress(localPath) {
  const folderName = path.basename(localPath);

  // create a file to stream archive data to.
  const outDir = path.resolve(localPath, '../', `${folderName}.zip`);
  const output = fs.createWriteStream(outDir);
  const archive = archiver('zip', {
    zlib: { level: 9 } // Sets the compression level.
  });

  // listen for all archive data to be written
  // 'close' event is fired only when a file descriptor is involved
  output.on('close', function() {
    console.log(archive.pointer() + ' total bytes');
    console.log('archiver has been finalized and the output file descriptor has closed.');
  });

  // This event is fired when the data source is drained no matter what was the data source.
  // It is not part of this library but rather from the NodeJS Stream API.
  // @see: https://nodejs.org/api/stream.html#stream_event_end
  output.on('end', function() {
    console.log('Data has been drained');
  });

  // good practice to catch warnings (ie stat failures and other non-blocking errors)
  archive.on('warning', function(err) {
    if (err.code === 'ENOENT') {
      // log warning
    } else {
      // throw error
      throw err;
    }
  });

  // good practice to catch this error explicitly
  archive.on('error', function(err) {
    throw err;
  });

  // pipe archive data to the file
  archive.pipe(output);
  await compressDir(archive, localPath);
  await archive.finalize();
  return outDir;
}


/**
 * å‹ç¼©æ–‡ä»¶ã€æ–‡ä»¶å¤¹
 *
 * @param {*} archive
 * @param {*} dir
 */
function compressDir(archive, dir) {
  return new Promise((resolve, reject) => {
    fs.stat(dir, (err,data)=>{
      if (err){
        reject(err);
        return console.log(err);
      }
      const filename = path.basename(dir);
      // å¦‚æœæ˜¯æ–‡ä»¶å¤¹ åˆ™å‹ç¼©è¯¥æ–‡ä»¶å¤¹
      if (data.isDirectory()) {
        archive.directory(dir, filename);
      } else {
        // å¦åˆ™å‹ç¼©è¯¥æ–‡ä»¶
        archive.append(fs.createReadStream(dir), { name: filename });
      }
      resolve(true);
    })
  })
}


/**
 * è¯»å–nodeå‘½ä»¤çš„æŒ‡å®šå‚æ•°
 *
 * @param {*} target
 * @return {*} 
 */
function resolveArgs(...target) {
  let args;
  try {
    args = JSON.parse(process.env.npm_config_argv).original
  } catch(e) {
    throw new Error(e);
  }
  const res = {};
  target.forEach((field) => {
    args.forEach((arg, index) => {
      const keyVals = arg.split('=');
      if (keyVals?.[0] == field) {
        res[field.split('--')[1]] = keyVals[1];
        args.splice(index, 1);
      }
    });
  })
  return res;
}

function deploy() {
  console.log("ğŸš€ğŸš€ğŸš€ start deploying...");

  // è¯»å–nodeå‘½ä»¤çš„å‚æ•° æ¥è·å–é“¾æ¥è¿œç¨‹LinuxæœåŠ¡å™¨çš„ç”¨æˆ·åå’Œå¯†ç 
  const args = resolveArgs("--username", "--password");

  // è¯»å–ç”¨æˆ·çš„é»˜è®¤é…ç½®æ–‡ä»¶ .deploy.config.json
  const config = readConfigFile();
  const conn = new Client();
  conn.on('ready', () => {
    console.log('Client :: ready');
    const localPath = path.resolve(cwdPath, config.localPath);
    const folderName = path.basename(localPath);
    compress(localPath).then((outDir) => {
      const zipFileName = path.basename(outDir);
      let p = config.remotePath;
      p = p.replace(/\/+$/, '');
      const remotePath = p + '/' + zipFileName;
      console.log(outDir, remotePath);
      uploadFile(conn, outDir, remotePath, (res) => {
        console.log('ä¸Šä¼ æˆåŠŸï¼', res === undefined ? '' : res);
        console.log('å¼€å§‹è§£å‹æ–‡ä»¶...');
        // æ‰§è¡Œshellè„šæœ¬å‘½ä»¤
        conn.shell((err, stream) => {
          if (err) throw err;
          stream.on('close', () => {
            console.log('Stream :: close');
            console.log('æ–‡ä»¶è§£å‹å®Œæ¯•ï¼\néƒ¨ç½²å®Œæˆï¼ğŸ¢ğŸ¢ğŸ¢');
            conn.end();
          });
          stream.pipe(process.stdout)
          // TODO: mv ${folderName} ${folderName + '-' + Date.now()}
          // è¿›å…¥æŒ‡å®šæ–‡ä»¶å¤¹è§£å‹ç¼©æ–‡ä»¶åˆ°å½“å‰æ–‡ä»¶å¤¹ å¹¶åˆ é™¤å‹ç¼©åŒ…
          // æ‰§è¡Œè‡ªå®šä¹‰è„šæœ¬
          const scripsts = config.shellScripts === undefined ? '' : config.shellScripts;
          stream.end(`cd ${p}\nrm -rf ${folderName}\njar xvf ${zipFileName}&&rm -rf ${zipFileName}\n${scripsts}\nexit\n`);
        });
      });
    })
  }).connect({
    readyTimeout: 20000,
    ...config,
    ...args
  });
}

module.exports = deploy;